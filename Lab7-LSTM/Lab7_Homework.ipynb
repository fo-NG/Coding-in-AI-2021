{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.4"
    },
    "colab": {
      "name": "Lab8_Homework.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jomGrnTqvzY2"
      },
      "source": [
        "# Lab 8: Training Deep Recurrent Neural Network - Part 2\n",
        "\n",
        "Name1, Student's ID1<br>\n",
        "Name2, Student's ID2<br>\n",
        "\n",
        "**Note: Please name your file**\n",
        "\n",
        "## Lab Instruction - Language Modelling and Text Classification\n",
        "\n",
        "In this lab, you will learn to train a deep recurrent neural network using LSTM with the Keras library using the Tensorflow backend. Your task is to implement the natural language modelling and text generation.\n",
        "\n",
        "Select your favourite book from https://www.gutenberg.org/browse/scores/top and download it as a text file. Then, you will train your language model using RNN-LSTM. \n",
        "\n",
        "- Language model (in Thai): http://bit.ly/language_model_1\n",
        "- Tutorial on how to create a language model (in English): https://medium.com/@shivambansal36/language-modelling-text-generation-using-lstms-deep-learning-for-nlp-ed36b224b275\n",
        "\n",
        "To evaluate the model, the perplexity measurement is used: https://stats.stackexchange.com/questions/10302/what-is-perplexity\n",
        "\n",
        "Last, fine-tune your model. You have to try different hyperparameter or adding more data. Discuss your result.\n",
        "\n",
        "\n",
        "\n",
        "**The total lab score is 15 which will be evaluated as follows:**</br>\n",
        "1. Specification (Do as the instruction said. This include the model tuning section where you have to do a proper amount of tuning) - 7 points\n",
        "2. Design of logic (No weired things in the process) -  4points\n",
        "3. Journaling (Communicate your thought process, comment your code, and discuss result & analyse **in every step**) - 4 points\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mwoJBrLKvzY6"
      },
      "source": [
        "#### 1. Load your data "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bcWCFsnfvzY7"
      },
      "source": [
        "# Import require library\n",
        "from keras import *\n",
        "from keras.preprocessing import text\n",
        "from keras.preprocessing import sequence\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import _utils as fn\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow import keras"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qksGjaIJvzZJ"
      },
      "source": [
        "#### 2. Data Preprocessing \n",
        "\n",
        "*Note that only story will be used as a dataset, footnote and creddit are not include.*\n",
        "\n",
        "The symbol '\\n' is indicated the end of the line ``<EOS>``, which is for our model to end the sentence here.\n",
        "\n",
        "To create a corpus for your model. The following code is can be used:</br>\n",
        "*Note that other techniques can be used*\n",
        "\n",
        "```python\n",
        "# cut the text in semi-redundant sequences of maxlen characters.\n",
        "for i in range(0, len(text) - maxlen, step):\n",
        "    sentences.append(text[i: i + maxlen])\n",
        "    next_chars.append(text[i + maxlen])\n",
        "```\n",
        "\n",
        "The code loop through the data from first word to the last word. The maxlen define a next n word for a model to predict.\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "id": "hZgohQbPvzZJ"
      },
      "source": [
        "# Preprocessing \n",
        "# Create corpus & Word vectorization\n",
        "\n",
        "# Preprocessing \n",
        "#maps chars to integers\n",
        "chars = sorted(list(set(data)))\n",
        "char_index = dict((c, i) for i, c in enumerate(chars))\n",
        "index_char = dict((i, c) for i, c in enumerate(chars))\n",
        "\n",
        "maxlen = 100\n",
        "step = 3\n",
        "sentences = []\n",
        "next_chars = []\n",
        "for i in range(0, len(data) - maxlen, step):\n",
        "    sentences.append(data[i: i + maxlen])\n",
        "    next_chars.append(data[i + maxlen])\n",
        "\n",
        "\n",
        "# Create corpus & Word vectorization\n",
        "x = np.zeros((len(sentences), maxlen, len(chars)), dtype=np.bool)\n",
        "y = np.zeros((len(sentences), len(chars)), dtype=np.bool)\n",
        "for i, sentence in enumerate(sentences):\n",
        "    for t, char in enumerate(sentence):\n",
        "        #encode features\n",
        "        x[i, t, char_index[char]] = 1\n",
        "        y[i, char_index[next_chars[i]]] = 1\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c-ry6hn0vzZc"
      },
      "source": [
        "#### 3. Language Model\n",
        "\n",
        "Define RNN model using LSTM and word embedding representation</br>\n",
        "We will used perplexity as a metrics\n",
        "\n",
        "```python\n",
        "def perplexity(y_true, y_pred):\n",
        "    cross_entropy = keras.backend.categorical_crossentropy(y_true, y_pred)\n",
        "    perplexity = keras.backend.pow(2.0, cross_entropy)\n",
        "    return perplexity\n",
        "```\n",
        "\n",
        "To used custom metrics function > https://keras.io/metrics/\n",
        "\n",
        "For a loss function `categorical_crossentropy` is used, any optimzation method can be applied."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wvwPzZo8uJXv"
      },
      "source": [
        "\n",
        "In this lab, we will used perplexity as a metrics\n",
        "\n",
        "\n",
        "```\n",
        "def perplexity(y_true, y_pred):\n",
        "    cross_entropy = keras.backend.categorical_crossentropy(y_true, y_pred)\n",
        "    perplexity = keras.backend.pow(2.0, cross_entropy)\n",
        "    return perplexity\n",
        "```\n",
        "\n",
        "\n",
        "To used custom metrics function > https://keras.io/metrics/"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xDOBkmNYvzZf"
      },
      "source": [
        "def perplexity(y_true, y_pred):\n",
        "    cross_entropy = keras.backend.categorical_crossentropy(y_true, y_pred)\n",
        "    perplexity = keras.backend.pow(2.0, cross_entropy)\n",
        "    return perplexity"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "65pM7pqNvzZm"
      },
      "source": [
        "# Define your model\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-uZwRT6RvzZu"
      },
      "source": [
        "#### 4. Evaluate your model "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9g4DkVi3vzZv"
      },
      "source": [
        "\n",
        "# Create a function to evaluate your model using perplexity measurment (You can try adding other measurements as well)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J6-pIYam3ACT",
        "outputId": "8cc672f6-4fb7-403c-8d57-841e7bcca108"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "893/893 [==============================] - 32s 35ms/step - loss: 3.1300 - perplexity: 17.0582\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XCU3FZjsvzZy"
      },
      "source": [
        "#### 5. Text generating"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jAd1Kdl3vzZz"
      },
      "source": [
        "\n",
        "    \n",
        "def generate_text(seedtext, next_words, max_sequence_len, model):\n",
        "  for j in range(next_words):\n",
        "    token_list = tokenizer.texts_to_sequences([seedtext])[0]\n",
        "    token_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n",
        "    #predicted = model.predict_classes(token_list, verbose=0)\n",
        "    predict_x=model.predict(token_list) \n",
        "    predicted =np.argmax(predict_x,axis=1)\n",
        "\n",
        "    output_word = \"\"\n",
        "    for word, index in tokenizer.word_index.items():\n",
        "      if index == predicted:\n",
        "        output_word = word\n",
        "        break\n",
        "    seedtext +=\" \" + output_word\n",
        "  return seedtext"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yC3AVscmvzZ4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c601d25e-1aac-418c-dcfe-cbfd4cb60a37"
      },
      "source": [
        "# generate your sample text\n",
        "\n",
        "seed_text = input('Enter your start sentence:')\n",
        "#generate_text , Input , Num_next_word,Max_sequence,Model\n",
        "gen_text = generate_text(seed_text,10,max_sequence_len,model)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter your start sentence:love\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 111) for input KerasTensor(type_spec=TensorSpec(shape=(None, 111), dtype=tf.float32, name='Embedding_input'), name='Embedding_input', description=\"created by layer 'Embedding_input'\"), but it was called on an input with incompatible shape (None, 9).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2_F4yLX2vzZ9"
      },
      "source": [
        "# Try out different hyperparameter & model architecture"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mNoHjlejvzaB"
      },
      "source": [
        "####[Speacial] 7. Help your model to generate a short story \n",
        "\n",
        "**Example** https://medium.com/deep-writing/harry-potter-written-by-artificial-intelligence-8a9431803da6\n",
        "\n",
        "Write your result in a `markdown` cell"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_9tjrUmHvzaC"
      },
      "source": [
        "# Create your short-story from your model (Add your creativity here)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fLz1ABUgvzaI"
      },
      "source": [
        "### More on Natural language Processing and Language model\n",
        "1. https://medium.com/@ageitgey/natural-language-processing-is-fun-9a0bff37854e \n",
        "2. https://medium.com/phrasee/neural-text-generation-generating-text-using-conditional-language-models-a37b69c7cd4b\n",
        "3. http://karpathy.github.io/2015/05/21/rnn-effectiveness/\n",
        "\n",
        "**Music generates by RNN**\n",
        "https://soundcloud.com/optometrist-prime/recurrence-music-written-by-a-recurrent-neural-network\n"
      ]
    }
  ]
}